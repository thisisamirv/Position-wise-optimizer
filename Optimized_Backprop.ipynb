{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-3ttZRN0AS35"
      },
      "outputs": [],
      "source": [
        "# Import packages\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import requests\n",
        "import gzip\n",
        "import os\n",
        "import hashlib\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPkbeYfTAeI1"
      },
      "outputs": [],
      "source": [
        "# Dataset 1 - Cat vs non-cat, binary classification\n",
        "\n",
        "train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
        "train_x = np.array(train_dataset[\"train_set_x\"][:])\n",
        "train_y = np.array(train_dataset[\"train_set_y\"][:])\n",
        "\n",
        "Y = train_y.reshape((1, train_y.shape[0]))\n",
        "train_x_flatten = train_x.reshape(train_x.shape[0], -1).T\n",
        "X = train_x_flatten / 255.\n",
        "X_f = X.astype(np.float32)\n",
        "Y_f = Y.astype(np.float32)\n",
        "X_T = (torch.from_numpy(X_f.T)).clone().detach().requires_grad_(True)\n",
        "Y_T = (torch.from_numpy(Y_f.T)).clone().detach().requires_grad_(True)\n",
        "Data_num =\"Data1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7j2vHjoxEarX"
      },
      "outputs": [],
      "source": [
        "# Dataset 2 - MNIST digits, multi-categorical classification\n",
        "\n",
        "path = ''\n",
        "def fetch(url):\n",
        "    fp = os.path.join(path, hashlib.md5(url.encode('utf-8')).hexdigest())\n",
        "    if os.path.isfile(fp):\n",
        "        with open(fp, \"rb\") as f:\n",
        "            data = f.read()\n",
        "    else:\n",
        "        with open(fp, \"wb\") as f:\n",
        "            data = requests.get(url).content\n",
        "            f.write(data)\n",
        "    return np.frombuffer(gzip.decompress(data), dtype=np.uint8).copy()\n",
        "\n",
        "X = fetch(\"http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\")[0x10:].reshape((-1, 28, 28))\n",
        "Y = fetch(\"http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\")[8:]\n",
        "train_x = np.copy(X)\n",
        "train_y = np.copy(Y)\n",
        "Y = train_y.reshape(-1)\n",
        "nb_classes = 10\n",
        "Y = (np.eye(nb_classes)[Y]).T\n",
        "X = X.reshape(X.shape[0], -1).T\n",
        "Y = Y.astype(np.float32)\n",
        "X = X.astype(np.float32)\n",
        "X = (torch.from_numpy(X)).clone().detach().requires_grad_(True)\n",
        "Y = (torch.from_numpy(Y)).clone().detach().requires_grad_(True)\n",
        "Data_num = \"Data2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HGsjFrlJxYk"
      },
      "outputs": [],
      "source": [
        "# Dataset 3 - Pima Indians Diabetes, binary classification\n",
        "\n",
        "Url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv'\n",
        "file_pd = pd.read_csv(Url, sep = \",\")\n",
        "Data_file = file_pd.to_numpy()\n",
        "train_x = Data_file[:, :8]\n",
        "train_y = Data_file[:, 8:]\n",
        "X = train_x.reshape(train_x.shape[0], -1).T\n",
        "Y = train_y.T\n",
        "Data_num = \"Data3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARxj2K7VzKh4"
      },
      "outputs": [],
      "source": [
        "# Dataset 4 - Banknote, binary classification\n",
        "Url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt'\n",
        "file_pd = pd.read_csv(Url, sep = \",\")\n",
        "Data_file = file_pd.to_numpy()\n",
        "train_x = Data_file[:, :4]\n",
        "train_y = Data_file[:, 4:]\n",
        "X = train_x.reshape(train_x.shape[0], -1).T\n",
        "Y = train_y.T\n",
        "Data_num = \"Data4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lTbPe24hD6w"
      },
      "outputs": [],
      "source": [
        "# Dataset 5 - Boston House Price, regression problem\n",
        "Url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.data'\n",
        "file_pd = pd.read_csv(Url, delim_whitespace = True, header = None)\n",
        "Data_file = file_pd.to_numpy()\n",
        "train_x = Data_file[:, :13]\n",
        "train_y = Data_file[:, 13:]\n",
        "X = train_x.reshape(train_x.shape[0], -1).T\n",
        "Y = train_y.T\n",
        "Data_num = \"Data5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z6rTV8Siowad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y shape: torch.Size([10, 60000])\n",
            "X shape: torch.Size([784, 60000])\n",
            "Number of training examples: 60000\n"
          ]
        }
      ],
      "source": [
        "# Specify dataset and its specific attributes\n",
        "\n",
        "## Loss goal\n",
        "def C_limit(Data_num):\n",
        "  if Data_num == \"Data1\":\n",
        "    cost_lim = 0.3\n",
        "    return cost_lim\n",
        "  elif Data_num == \"Data2\":\n",
        "    cost_lim = 3.2494\n",
        "    return cost_lim\n",
        "  elif Data_num == \"Data3\":\n",
        "    cost_lim = 0.55\n",
        "    return cost_lim\n",
        "  elif Data_num == \"Data4\":\n",
        "    cost_lim = 0.001\n",
        "    return cost_lim\n",
        "  elif Data_num == \"Data5\":\n",
        "    cost_lim = 84.42\n",
        "    return cost_lim\n",
        "\n",
        "cost_lim = C_limit(Data_num)\n",
        "\n",
        "## Cost calculation\n",
        "def Cost_cal (Data_num, Y, A4):\n",
        "  if Data_num == \"Data5\":\n",
        "    cost = (1 / Y.shape[1]) * torch.sum((Y - A4)**2)\n",
        "    return cost\n",
        "  else:\n",
        "    cost = (-1 / Y.shape[1]) * torch.sum(torch.multiply(Y, torch.log(A4)) + torch.multiply(1 - Y, torch.log(1 - A4)))\n",
        "    return cost\n",
        "\n",
        "## Output activation function\n",
        "def L_layer(Data_num, Z4):\n",
        "  if Data_num == \"Data2\":\n",
        "    #e_x = torch.exp(Z4 - torch.max(Z4))\n",
        "    #A4 = e_x / torch.sum(e_x, axis = 0)\n",
        "    A4 = F.softmax(Z4, dim = 0)\n",
        "    return A4\n",
        "  elif Data_num == \"Data5\":\n",
        "    A4 = Z4\n",
        "    return A4\n",
        "  else:\n",
        "    A4 = 1 / (1 + torch.Tensor.exp(-Z4))\n",
        "    return A4\n",
        "\n",
        "## Cost plot y axis limits\n",
        "if Data_num == \"Data1\":\n",
        "  ylim_top = 0.7\n",
        "  ylim_bottom = 0.3\n",
        "elif Data_num == \"Data2\":\n",
        "  ylim_top = 3.25\n",
        "  ylim_bottom = 3.2490\n",
        "elif Data_num == \"Data3\":\n",
        "  ylim_top = 0.7\n",
        "  ylim_bottom = 0.55\n",
        "elif Data_num == \"Data4\":\n",
        "  ylim_top = 0.01\n",
        "  ylim_bottom = 0.001\n",
        "elif Data_num == \"Data5\":\n",
        "  ylim_top = 120\n",
        "  ylim_bottom = 84.42\n",
        "\n",
        "## Print shapes of X, Y, and number of training examples\n",
        "print(\"Y shape: \" + str(Y.shape))\n",
        "print(\"X shape: \" + str(X.shape))\n",
        "print(\"Number of training examples: \" + str(X.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_O13Yq1TAnEN"
      },
      "outputs": [],
      "source": [
        "# Initialize model parameters\n",
        "\n",
        "## Set seed\n",
        "torch.manual_seed(1)\n",
        "\n",
        "## NN layers and learning rate\n",
        "L = [torch.tensor([X.shape[0]]), torch.tensor([20]), torch.tensor([7]), torch.tensor([5]), torch.tensor([Y.shape[0]])]\n",
        "learning_rate = 0.0075\n",
        "\n",
        "## Initialize weights and biases\n",
        "W_c = {}; W_p = {}; W_o = {}; b_c = {}; b_p = {}; b_o = {}\n",
        "for l in range(1, len(L)):\n",
        "  W_c[\"W_c%s\" %(l)] = torch.randn(L[l], L[l-1]) / torch.sqrt(L[l-1])\n",
        "  W_p[\"W_p%s\" %(l)] = W_c[\"W_c%s\" %(l)].detach().clone()\n",
        "  W_o[\"W_o%s\" %(l)] = W_c[\"W_c%s\" %(l)].detach().clone()\n",
        "  b_c[\"b_c%s\" %(l)] = torch.zeros((L[l], 1))\n",
        "  b_p[\"b_p%s\" %(l)] = b_c[\"b_c%s\" %(l)].detach().clone()\n",
        "  b_o[\"b_o%s\" %(l)] = b_c[\"b_c%s\" %(l)].detach().clone()\n",
        "\n",
        "## Initialize cost lists\n",
        "cost_list_c = []; cost_list_p = []; cost_list_o = []\n",
        "\n",
        "## Construct PyToch model\n",
        "class Data(Dataset):\n",
        "  # Constructor\n",
        "  def __init__(self, X, Y):\n",
        "    self.x = X\n",
        "    self.y = Y\n",
        "    self.len = self.x.shape[0]  \n",
        "  # Getter\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "  # Get Length\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "class CBP(nn.Module):\n",
        "  def __init__(self, layer_dims):\n",
        "    super(CBP, self).__init__()\n",
        "    self.l1 = nn.Linear(layer_dims[0], layer_dims[1])\n",
        "    self.l2 = nn.Linear(layer_dims[1], layer_dims[2])\n",
        "    self.l3 = nn.Linear(layer_dims[2], layer_dims[3])\n",
        "    self.l4 = nn.Linear(layer_dims[3], layer_dims[4])\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.l1(x))\n",
        "    x = torch.relu(self.l2(x))\n",
        "    x = torch.relu(self.l3(x))\n",
        "    x = torch.sigmoid(self.l4(x))\n",
        "    return x\n",
        "\n",
        "def train(model, criterion, x, y, optimizer, cost_lim):\n",
        "  cost_list_p = []\n",
        "  cost = 0\n",
        "  j = 0\n",
        "   \n",
        "  for i in range(10000):\n",
        "    optimizer.zero_grad()\n",
        "    yhat = model(x)\n",
        "    loss = criterion(yhat, y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    cost = loss.item()\n",
        "    cost_list_p.append(cost)\n",
        "    if j % 250 == 0:\n",
        "      print(\"Cost for PyTorch backprop after iteration {}: {}\".format((j), cost))\n",
        "    j += 1\n",
        "    if cost < cost_lim:\n",
        "      last_j_p = j\n",
        "      print(\"Cost for PyTorch backprop after iteration {}: {}\".format((j), cost))\n",
        "      print(\"Number of epochs for PyTorch backprop: \" + str(last_j_p))\n",
        "      break\n",
        "  return cost_list_p, last_j_p\n",
        "\n",
        "model = CBP(L)\n",
        "\n",
        "model.l1.weight = torch.nn.parameter.Parameter(W_p[\"W_p1\"].float())\n",
        "model.l1.bias = torch.nn.parameter.Parameter(b_p[\"b_p1\"][0].float())\n",
        "model.l2.weight = torch.nn.parameter.Parameter(W_p[\"W_p2\"].float())\n",
        "model.l2.bias = torch.nn.parameter.Parameter(b_p[\"b_p2\"][0].float())\n",
        "model.l3.weight = torch.nn.parameter.Parameter(W_p[\"W_p3\"].float())\n",
        "model.l3.bias = torch.nn.parameter.Parameter(b_p[\"b_p3\"][0].float())\n",
        "model.l4.weight = torch.nn.parameter.Parameter(W_p[\"W_p4\"].float())\n",
        "model.l4.bias = torch.nn.parameter.Parameter(b_p[\"b_p4\"][0].float())\n",
        "\n",
        "data_set = Data(X, Y)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QgLlFn1TAsvK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost for conventional backprop after iteration 0: nan\n",
            "Cost for conventional backprop after iteration 9: 3.2490532398223877\n",
            "Number of epochs for conventional backprop: 9\n",
            "Time elapsed for optimized backprop:  2.7472960000000004\n"
          ]
        }
      ],
      "source": [
        "# 3 algorithms: Conventional, PyTorch, and Optimized backpropagation\n",
        "\n",
        "\n",
        "\n",
        "Conventional_Backprop = \"\"\"\n",
        "t0 = time.process_time()\n",
        "i = 0\n",
        "for i in range(10000):\n",
        "    Z_c1 = torch.mm(W_c[\"W_c1\"], X) + b_c[\"b_c1\"]\n",
        "    A_c1 = torch.maximum(torch.tensor([0]), Z_c1)\n",
        "    Z_c2 = torch.mm(W_c[\"W_c2\"], A_c1) + b_c[\"b_c2\"]\n",
        "    A_c2 = torch.maximum(torch.tensor([0]), Z_c2)\n",
        "    Z_c3 = torch.mm(W_c[\"W_c3\"], A_c2) + b_c[\"b_c3\"]\n",
        "    A_c3 = torch.maximum(torch.tensor([0]), Z_c3)\n",
        "    Z_c4 = torch.mm(W_c[\"W_c4\"], A_c3) + b_c[\"b_c4\"]\n",
        "    A_c4 = L_layer(Data_num, Z_c4)\n",
        "\n",
        "    dZ_c4 = torch.subtract(A_c4, Y)\n",
        "    dW_c4 = torch.mm(dZ_c4, A_c3.T) * (1. / A_c3.shape[1])\n",
        "    db_c4 = torch.sum(dZ_c4, axis = 1, keepdims = True) * (1. / A_c3.shape[1])\n",
        "\n",
        "    dA_c3 = torch.mm(W_c[\"W_c4\"].T, dZ_c4)\n",
        "    dZ_c3 = torch.clone(dA_c3)\n",
        "    dZ_c3[Z_c3 <= 0] = 0\n",
        "    dW_c3 = torch.mm(dZ_c3, A_c2.T) * (1. / A_c2.shape[1])\n",
        "    db_c3 = torch.sum(dZ_c3, axis = 1, keepdims = True) * (1. / A_c2.shape[1])\n",
        "\n",
        "    dA_c2 = torch.mm(W_c[\"W_c3\"].T, dZ_c3)\n",
        "    dZ_c2 = torch.clone(dA_c2)\n",
        "    dZ_c2[Z_c2 <= 0] = 0\n",
        "    dW_c2 = torch.mm(dZ_c2, A_c1.T) * (1. / A_c1.shape[1])\n",
        "    db_c2 = torch.sum(dZ_c2, axis = 1, keepdims = True) * (1. / A_c1.shape[1])\n",
        "\n",
        "    dA_c1 = torch.mm(W_c[\"W_c2\"].T, dZ_c2)\n",
        "    dZ_c1 = torch.clone(dA_c1)\n",
        "    dZ_c1[Z_c1 <= 0] = 0\n",
        "    dW_c1 = torch.mm(dZ_c1, X.T) * (1. / X.shape[1])\n",
        "    db_c1 = torch.sum(dZ_c1, axis = 1, keepdims = True) * (1. / X.shape[1])\n",
        "\n",
        "    W_c[\"W_c1\"] = torch.subtract(W_c[\"W_c1\"], learning_rate * dW_c1)\n",
        "    b_c[\"b_c1\"] = torch.subtract(b_c[\"b_c1\"], learning_rate * db_c1)\n",
        "    W_c[\"W_c2\"] = torch.subtract(W_c[\"W_c2\"], learning_rate * dW_c2)\n",
        "    b_c[\"b_c2\"] = torch.subtract(b_c[\"b_c2\"], learning_rate * db_c2)\n",
        "    W_c[\"W_c3\"] = torch.subtract(W_c[\"W_c3\"], learning_rate * dW_c3)\n",
        "    b_c[\"b_c3\"] = torch.subtract(b_c[\"b_c3\"], learning_rate * db_c3)\n",
        "    W_c[\"W_c4\"] = torch.subtract(W_c[\"W_c4\"], learning_rate * dW_c4)\n",
        "    b_c[\"b_c4\"] = torch.subtract(b_c[\"b_c4\"], learning_rate * db_c4)\n",
        "\n",
        "    cost_c = Cost_cal(Data_num, Y, A_c4)\n",
        "    cost_c = np.squeeze(cost_c)\n",
        "    cost_list_c.append(cost_c)\n",
        "\n",
        "    if i % 250 == 0:\n",
        "        print(\"Cost for conventional backprop after iteration {}: {}\".format(i, cost_c))\n",
        "    \n",
        "    if cost_c < cost_lim:\n",
        "        last_i_c = i\n",
        "        print(\"Cost for conventional backprop after iteration {}: {}\".format(i, cost_c))\n",
        "        print(\"Number of epochs for conventional backprop: \" + str(last_i_c))\n",
        "        break\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    i = i + 1\n",
        "\n",
        "t1 = time.process_time() - t0\n",
        "print(\"Time elapsed for conventional backprop: \", t1)\n",
        "print()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "PyTorch_Backprop = \"\"\"\n",
        "t2 = time.process_time()\n",
        "\n",
        "cost_list_p, last_i_p = train(model, criterion, X.T, Y.T, optimizer, cost_lim)\n",
        "\n",
        "t3 = time.process_time() - t2\n",
        "print(\"Time elapsed for PyTorch backprop: \", t3)\n",
        "print()\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "Optimized_Backprop = \"\"\"\n",
        "t4 = time.process_time()\n",
        "\n",
        "for k in range(10000):\n",
        "    Z_o1 = torch.mm(W_o[\"W_o1\"], X) + b_o[\"b_o1\"]\n",
        "    A_o1 = torch.maximum(torch.tensor([0]), Z_o1)\n",
        "    Z_o2 = torch.mm(W_o[\"W_o2\"], A_o1) + b_o[\"b_o2\"]\n",
        "    A_o2 = torch.maximum(torch.tensor([0]), Z_o2)\n",
        "    Z_o3 = torch.mm(W_o[\"W_o3\"], A_o2) + b_o[\"b_o3\"]\n",
        "    A_o3 = torch.maximum(torch.tensor([0]), Z_o3)\n",
        "    Z_o4 = torch.mm(W_o[\"W_o4\"], A_o3) + b_o[\"b_o4\"]\n",
        "    A_o4 = L_layer(Data_num, Z_o4)\n",
        "\n",
        "    dZ_o4 = torch.subtract(A_o4, Y)\n",
        "    dW_o4 = torch.mm(dZ_o4, A_o3.T) * (1. / A_o3.shape[1])\n",
        "    db_o4 = torch.sum(dZ_o4, axis = 1, keepdims = True) * (1. / A_o3.shape[1])\n",
        "    W_o[\"W_o4\"] = torch.subtract(W_o[\"W_o4\"], learning_rate * dW_o4)\n",
        "    b_o[\"b_o4\"] = torch.subtract(b_o[\"b_o4\"], learning_rate * db_o4)\n",
        "    Z_o4 = torch.mm(W_o[\"W_o4\"], A_o3) + b_o[\"b_o4\"]\n",
        "    A_o4 = L_layer(Data_num, Z_o4)\n",
        "\n",
        "    dZ_o4 = torch.subtract(A_o4, Y)\n",
        "    dW_o4 = torch.mm(dZ_o4, A_o3.T) * (1. / A_o3.shape[1])\n",
        "    db_o4 = torch.sum(dZ_o4, axis = 1, keepdims = True) * (1. / A_o3.shape[1])\n",
        "    dA_o3 = torch.mm(W_o[\"W_o4\"].T, dZ_o4)\n",
        "    dZ_o3 = torch.clone(dA_o3)\n",
        "    dZ_o3[Z_o3 <= 0] = 0\n",
        "    dW_o3 = torch.mm(dZ_o3, A_o2.T) * (1. / A_o2.shape[1])\n",
        "    db_o3 = torch.sum(dZ_o3, axis = 1, keepdims = True) * (1. / A_o2.shape[1])\n",
        "    W_o[\"W_o3\"] = torch.subtract(W_o[\"W_o3\"], learning_rate * dW_o3)\n",
        "    b_o[\"b_o3\"] = torch.subtract(b_o[\"b_o3\"], learning_rate * db_o3)\n",
        "    W_o[\"W_o4\"] = torch.subtract(W_o[\"W_o4\"], learning_rate * dW_o4)\n",
        "    b_o[\"b_o4\"] = torch.subtract(b_o[\"b_o4\"], learning_rate * db_o4)\n",
        "    Z_o3 = torch.mm(W_o[\"W_o3\"], A_o2) + b_o[\"b_o3\"]\n",
        "    A_o3 = torch.maximum(torch.tensor([0]), Z_o3)\n",
        "    Z_o4 = torch.mm(W_o[\"W_o4\"], A_o3) + b_o[\"b_o4\"]\n",
        "    A_o4 = L_layer(Data_num, Z_o4)\n",
        "\n",
        "    dZ_o4 = torch.subtract(A_o4, Y)\n",
        "    dW_o4 = torch.mm(dZ_o4, A_o3.T) * (1. / A_o3.shape[1])\n",
        "    db_o4 = torch.sum(dZ_o4, axis = 1, keepdims = True) * (1. / A_o3.shape[1])\n",
        "    dA_o3 = torch.mm(W_o[\"W_o4\"].T, dZ_o4)\n",
        "    dZ_o3 = torch.clone(dA_o3)\n",
        "    dZ_o3[Z_o3 <= 0] = 0\n",
        "    dW_o3 = torch.mm(dZ_o3, A_o2.T) * (1. / A_o2.shape[1])\n",
        "    db_o3 = torch.sum(dZ_o3, axis = 1, keepdims = True) * (1. / A_o2.shape[1])\n",
        "    dA_o2 = torch.mm(W_o[\"W_o3\"].T, dZ_o3)\n",
        "    dZ_o2 = torch.clone(dA_o2)\n",
        "    dZ_o2[Z_o2 <= 0] = 0\n",
        "    dW_o2 = torch.mm(dZ_o2, A_o1.T) * (1. / A_o1.shape[1])\n",
        "    db_o2 = torch.sum(dZ_o2, axis = 1, keepdims = True) * (1. / A_o1.shape[1])\n",
        "    W_o[\"W_o2\"] = torch.subtract(W_o[\"W_o2\"], learning_rate * dW_o2)\n",
        "    b_o[\"b_o2\"] = torch.subtract(b_o[\"b_o2\"], learning_rate * db_o2)\n",
        "    W_o[\"W_o3\"] = torch.subtract(W_o[\"W_o3\"], learning_rate * dW_o3)\n",
        "    b_o[\"b_o3\"] = torch.subtract(b_o[\"b_o3\"], learning_rate * db_o3)\n",
        "    W_o[\"W_o4\"] = torch.subtract(W_o[\"W_o4\"], learning_rate * dW_o4)\n",
        "    b_o[\"b_o4\"] = torch.subtract(b_o[\"b_o4\"], learning_rate * db_o4)\n",
        "    Z_o2 = torch.mm(W_o[\"W_o2\"], A_o1) + b_o[\"b_o2\"]\n",
        "    A_o2 = torch.maximum(torch.tensor([0]), Z_o2)\n",
        "    Z_o3 = torch.mm(W_o[\"W_o3\"], A_o2) + b_o[\"b_o3\"]\n",
        "    A_o3 = torch.maximum(torch.tensor([0]), Z_o3)\n",
        "    Z_o4 = torch.mm(W_o[\"W_o4\"], A_o3) + b_o[\"b_o4\"]\n",
        "    A_o4 = L_layer(Data_num, Z_o4)\n",
        "\n",
        "    dZ_o4 = torch.subtract(A_o4, Y)\n",
        "    dW_o4 = torch.mm(dZ_o4, A_o3.T) * (1. / A_o3.shape[1])\n",
        "    db_o4 = torch.sum(dZ_o4, axis = 1, keepdims = True) * (1. / A_o3.shape[1])\n",
        "    dA_o3 = torch.mm(W_o[\"W_o4\"].T, dZ_o4)\n",
        "    dZ_o3 = torch.clone(dA_o3)\n",
        "    dZ_o3[Z_o3 <= 0] = 0\n",
        "    dW_o3 = torch.mm(dZ_o3, A_o2.T) * (1. / A_o2.shape[1])\n",
        "    db_o3 = torch.sum(dZ_o3, axis = 1, keepdims = True) * (1. / A_o2.shape[1])\n",
        "    dA_o2 = torch.mm(W_o[\"W_o3\"].T, dZ_o3)\n",
        "    dZ_o2 = torch.clone(dA_o2)\n",
        "    dZ_o2[Z_o2 <= 0] = 0\n",
        "    dW_o2 = torch.mm(dZ_o2, A_o1.T) * (1. / A_o1.shape[1])\n",
        "    db_o2 = torch.sum(dZ_o2, axis = 1, keepdims = True) * (1. / A_o1.shape[1])\n",
        "    dA_o1 = torch.mm(W_o[\"W_o2\"].T, dZ_o2)\n",
        "    dZ_o1 = torch.clone(dA_o1)\n",
        "    dZ_o1[Z_o1 <= 0] = 0\n",
        "    dW_o1 = torch.mm(dZ_o1, X.T) * (1. / X.shape[1])\n",
        "    db_o1 = torch.sum(dZ_o1, axis = 1, keepdims = True) * (1. / X.shape[1])\n",
        "    W_o[\"W_o1\"] = torch.subtract(W_o[\"W_o1\"], learning_rate * dW_o1)\n",
        "    b_o[\"b_o1\"] = torch.subtract(b_o[\"b_o1\"], learning_rate * db_o1)\n",
        "    W_o[\"W_o2\"] = torch.subtract(W_o[\"W_o2\"], learning_rate * dW_o2)\n",
        "    b_o[\"b_o2\"] = torch.subtract(b_o[\"b_o2\"], learning_rate * db_o2)\n",
        "    W_o[\"W_o3\"] = torch.subtract(W_o[\"W_o3\"], learning_rate * dW_o3)\n",
        "    b_o[\"b_o3\"] = torch.subtract(b_o[\"b_o3\"], learning_rate * db_o3)\n",
        "    W_o[\"W_o4\"] = torch.subtract(W_o[\"W_o4\"], learning_rate * dW_o4)\n",
        "    b_o[\"b_o4\"] = torch.subtract(b_o[\"b_o4\"], learning_rate * db_o4)\n",
        "\n",
        "    cost_o = Cost_cal(Data_num, Y, A_o4)\n",
        "    cost_o = np.squeeze(cost_o)\n",
        "    cost_list_o.append(cost_o)\n",
        "\n",
        "    if k % 250 == 0:\n",
        "        print(\"Cost for conventional backprop after iteration {}: {}\".format(k, cost_o))\n",
        "    \n",
        "    if cost_o < cost_lim:\n",
        "        last_k_o = k\n",
        "        print(\"Cost for conventional backprop after iteration {}: {}\".format(k, cost_o))\n",
        "        print(\"Number of epochs for conventional backprop: \" + str(last_k_o))\n",
        "        break\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    k = k + 1\n",
        "\n",
        "t5 = time.process_time() - t4\n",
        "print(\"Time elapsed for optimized backprop: \", t5)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "aP595FZA2jNO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cost for conventional backprop after iteration 0: nan\n",
            "Cost for conventional backprop after iteration 250: 3.250303268432617\n",
            "Cost for conventional backprop after iteration 500: 3.2499678134918213\n",
            "Cost for conventional backprop after iteration 750: 3.2497377395629883\n",
            "Cost for conventional backprop after iteration 1000: 3.2495808601379395\n"
          ]
        }
      ],
      "source": [
        "# Execute backprop algorithms\n",
        "\n",
        "exec(Conventional_Backprop)\n",
        "exec(PyTorch_Backprop)\n",
        "exec(Optimized_Backprop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlp28ze9BoUh"
      },
      "outputs": [],
      "source": [
        "# Plot cost functions\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.suptitle('Conventional Backprop', fontsize=25)\n",
        "plt.title(f\"Time elapsed: {t1: .2f} seconds \\n Number of epochs: {last_i_c}\", fontsize = 15)\n",
        "plt.plot(list(range(last_i_c + 1)), cost_list_c, color = 'blue')\n",
        "plt.ylim(bottom = ylim_bottom, top = ylim_top)\n",
        "plt.xlim(left = 0, right=last_i_c + 5)\n",
        "plt.xlabel(\"Epochs\", fontsize = 15)\n",
        "plt.ylabel(\"Cost\", fontsize = 15)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.suptitle('PyTorch Backprop', fontsize = 25)\n",
        "plt.title(f\"Time elapsed: {t3: .2f} seconds \\n Number of epochs : {last_j_p}\", fontsize = 15)\n",
        "plt.plot(list(range(last_j_p)), cost_list_p, color = 'green')\n",
        "plt.ylim(bottom = ylim_bottom, top = ylim_top)\n",
        "plt.xlim(left = 0, right = last_i_c + 5)\n",
        "plt.xlabel(\"Epochs\", fontsize = 15)\n",
        "plt.ylabel(\"Cost\", fontsize = 15)\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.suptitle('Optimized Backprop', fontsize = 25)\n",
        "plt.title(f\"Time elapsed: {t5:.2f} seconds \\n Number of epochs: {last_k_o}\", fontsize = 15)\n",
        "plt.plot(list(range(last_k_o + 1)), cost_list_o, color = 'red')\n",
        "plt.ylim(bottom = ylim_bottom, top = ylim_top)\n",
        "plt.xlim(left = 0, right = last_i_c + 5)\n",
        "plt.xlabel(\"Epochs\", fontsize = 15)\n",
        "plt.ylabel(\"Cost\", fontsize = 15)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Optimized Backprop.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
